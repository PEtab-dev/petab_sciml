var documenterSearchIndex = {"docs":
[{"location":"format.html#Format-Specification","page":"Format","title":"Format Specification","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"A PEtab SciML problem extends a standard version 2 PEtab problem to accommodate hybrid models SciML combining data-driven and mechanistic components. To this, the extension introduces one new file:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Neural Net Fil: YAML file(s) describing neural net model(s).","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"It also extends the following standard PEtab files to accommodate SciML models:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Mapping Table: Describes how neural network inputs and outputs map to PEtab quantities.\nParameters Table: Describes values and potential priors for initializing network parameters.\nCondition Table: Allows assigning neural network outputs and inputs.\nProblem YAML File: Includes a SciML field.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"All other PEtab files remain unchanged. ","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The main goal of the PEtab SciML extension is to enable hybrid models that combine data-driven and mechanistic components. There are three such hybrid model types, each specified differently:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Data-driven models in the ODE model’s right-hand side (RHS)\nDuring import, the SBML file is altered by either replacing a derivative or assigning a parameter to a neural network input.\nIn these cases, both the neural network inputs and outputs (as defined in the mapping table) must be assigned in the condition table with the setNetRate and/or setNetAssignment operatorType.\nData-driven models in the observable function\nThe output variable (as defined in the mapping table) is code directly in the observable formula.\nThe input variables (as defined in the mapping table) are assigned in the condition table with the setNetAssignment operatorType.\nData-driven models before the ODE model\nThese models set constant parameters or initial values in the ODE model prior to simulations.\nThe input can be defined in the mapping table or in the condition table.\nThe output variables (as defined in the mapping table) are assigned via the condition table.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"This page explains each file that is added or modified by the PEtab SciML extension, highlights its main functionality, and outlines the import logic for each supported hybrid model type.","category":"page"},{"location":"format.html#Neural-Network-Model-Format","page":"Format","title":"Neural Network Model Format","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"TODO: Dilan, I will need some help from you here, link the scheme?","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The neural network models are provided as separate YAML files that can be imported into a chosen neural-network package. Each YAML file has two main sections:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"layers: Defines the neural network layers, each with a unique ID. The layer names and argument syntax follow PyTorch conventions.\nforward: Describes the forward pass, indicating the order of layer calls and any activation functions.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Although these YAML files can be written manually, the recommended approach is to define a PyTorch nn.Module whose constructor sets up the layers and whose forward method outlines the layer calls. For example, a simple feed-forward network file can be created via:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer1 = nn.Linear(in_features=2, out_features=5)\n        self.layer2 = nn.Linear(in_features=5, out_features=5)\n        self.layer3 = nn.Linear(in_features=5, out_features=1)\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = F.tanh(x)\n        x = self.layer2(x)\n        x = F.tanh(x)\n        x = self.layer3(x)\n        return x","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Where the YAML file can then be generated with the petab_sciml library:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"# TODO: Add","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Any PyTorch-supported keyword can be supplied for each layer in the YAML file, and a wide range of layers are available. For instance, a more complex convolutional model might look like:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.max_pool1 = nn.MaxPool2d((2, 2))\n        self.fc1 = nn.Linear(64, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        self.flatten1 = nn.Flatten()\n\n    def forward(self, input):\n        c1 = self.conv1(input)\n        s2 = self.max_pool1(c1)\n        c3 = self.conv2(s2)\n        s4 = self.max_pool1(c3)\n        s4 = self.flatten1(s4)\n        f5 = self.fc1(s4)\n        f6 = self.fc2(f5)\n        output = self.fc3(f6)\n        return output","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"A complete list of supported and tested layers and activation functions can be found [ADD].","category":"page"},{"location":"format.html#Neural-Network-Parameters","page":"Format","title":"Neural Network Parameters","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"A subset of supported layers have parameters. In the PEtab SciML extension, all parameters for a neural network model are stored in an HDF5 file, with the file name specified in the parameter table. Each layer’s parameters are grouped under f.layerId, where layerId is the layer’s unique identifier. For example, the weights of a linear layer are stored at f.layerId.weight.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Since parameters are stored in an HDF5 format, they are stored as arrays. The indexing follows PyTorch conventions, meaning parameters are stored in row-major order. Typically, users do not need to manage these details manually, as PEtab SciML tools handle them automatically.","category":"page"},{"location":"format.html#Neural-Network-Input","page":"Format","title":"Neural Network Input","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"When network input is provided as an array via an HDF5 file (see the mapping table below), it should follow the PyTorch convention. For example, if the first layer is Conv2d, the input should be in (C, W, H) format, with data stored in row-major order. In general, the input should be structured to be directly compatible with PyTorch.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"tip: For developers: Respect memory order\nTools supporting the SciML extension should, for computational efficiency, reorder input data and potential layer parameter arrays to match the memory ordering of the target language. For example, PEtab.jl converts input data to column-major order, as used in Julia.","category":"page"},{"location":"format.html#Mapping-Table","page":"Format","title":"Mapping Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The mapping table describes how a neural network’s inputs and outputs map to PEtab problem variables.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\ne.g. \nk1 netId.input1","category":"page"},{"location":"format.html#Detailed-Field-Descriptions","page":"Format","title":"Detailed Field Descriptions","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId [STRING]: A valid PEtab identifier not defined elsewhere in the PEtab problem. It can be referenced in the condition, measurement, parameter, and observable tables or be a file, but not in the model itself. For neural network outputs, the PEtab identifier must be assigned in the condition table, whereas for inputs, this is not required (see examples below).\nmodelEntityId [STRING]: Describes the neural network entity corresponding to the petabEntityId. Must follow the format netId.input{n} or netId.output{n}, where n is the specific input or output index.","category":"page"},{"location":"format.html#Example:-Network-with-Scalar-Inputs","page":"Format","title":"Example: Network with Scalar Inputs","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Assume that the network net1 has two inputs, PEtab problem parameters net1_input1 and net1_input2. This would be specified as:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_input1 net1.input1\nnet1_input2 net1.input2","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"In particular, scalar inputs can be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Parameters in the parameters table: These may be either estimated or constant.\nAssigned in the condition table: This allows for condition-specific neural network inputs. Additionally, inputs can via the condition table be defined as equations, which is useful when the neural network is part of an ODE right-hand side.","category":"page"},{"location":"format.html#Example:-Network-with-Array-Inputs","page":"Format","title":"Example: Network with Array Inputs","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Sometimes, such as with image data, a neural network requires array input. In these cases, the input can be specified as an HDF5 file directly in the mapping table:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\ninput_net1.hf5 net1.input1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"As mentioned in [ADD], the HDF5 file should follow PyTorch indexing and be stored in row-major order.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"When there are multiple simulation conditions that each require a different neural network array input, the mapping table should map to a PEtab variable (e.g., net1_input):","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_input net1.input1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"This variable is then assigned to specific input files via the condition table. For a full example of a valid PEtab problem with array inputs, see [ADD].","category":"page"},{"location":"format.html#Example:-Network-Observable-Formula-Output","page":"Format","title":"Example: Network Observable Formula Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"If the neural network output appears in the observable formula, the PEtab entity should be directly referenced in the formula. For example:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_output1 net1.output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"A valid observable table would then be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"observableId observableFormula\nobs1 net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"As usual, the observableFormula can be any valid PEtab equation, so net1_output1 + 1 would also be valid.","category":"page"},{"location":"format.html#Example:-Network-Scalar-Output","page":"Format","title":"Example: Network Scalar Output","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"In addition to the observable formula, a neural network output can set a constant model parameter or be used in the ODE model right-hand side. In this case, the output is mapped to a PEtab parameter. For example:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"petabEntityId modelEntityId\nnet1_output1 net1.output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"The parameter (net1_output1) is then assigned in the condition table (see below), allowing anything from model parameters to derivatives to be set.","category":"page"},{"location":"format.html#Additional-Details","page":"Format","title":"Additional Details","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Although a neural network can, in principle, accept both array and scalar inputs, this feature is not currently tested for among tools implementing the PEtab SciML extension due to it being hard to implement. However, tools are free to add this feature.","category":"page"},{"location":"format.html#Condition-Table","page":"Format","title":"Condition Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"In the PEtab SciML extension, the condition table is extended to specify how neural network outputs (and, if needed, inputs) are assigned. To support this, two new operator types are introduced in operatorType:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"setNetRate: Assigns the rate of a species to a neural network output. In this case, targetValue must be a neural network output.\nsetNetAssignment: Assigns the input or output of a neural network in the ODE or observable formula.\nInput Case: targetId is a neural network input, and targetValue can be any valid math expression consisting of model variables.\nOutput Case: targetId is an ODE model parameter, and targetValue is a non-estimated model parameter that is replaced by the neural network output. Used to assign output in the ODE model RHS.","category":"page"},{"location":"format.html#Examples:-Specifying-Neural-Network-Output","page":"Format","title":"Examples: Specifying Neural Network Output","text":"","category":"section"},{"location":"format.html#Set-a-Constant-Model-Parameter","page":"Format","title":"Set a Constant Model Parameter","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Use the setValue operator. For example, if parameter p is determined by net1_output1 (mapped to a neural network output in the mapping table), write:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setValue p net1_output1","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"This approach allows for condition-specific assignments. For example, net1_output1 could target a different parameter in another condition or multiple parameters in the same condition.","category":"page"},{"location":"format.html#Set-an-Initial-Value","page":"Format","title":"Set an Initial Value","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Use the setInitial operator. For example, if the initial value of species X comes from net1_output1, write:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setInitial X net1_output1","category":"page"},{"location":"format.html#Set-a-Model-Derivative","page":"Format","title":"Set a Model Derivative","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Use the setNetRate operator. For example, if the derivative of X should be assigned to net1_output1, write:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetRate X net1_output1","category":"page"},{"location":"format.html#Alter-the-ODE-RHS","page":"Format","title":"Alter the ODE RHS","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Use the setNetAssignment operator. For example, if an ODE model parameter p should be given by net1_output1, write:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetAssignment p net1_output1","category":"page"},{"location":"format.html#Specifying-Neural-Network-Input","page":"Format","title":"Specifying Neural Network Input","text":"","category":"section"},{"location":"format.html#Neural-Network-Sets-Initial-Value(s)-or-Constant-Model-Parameter(s)","page":"Format","title":"Neural Network Sets Initial Value(s) or Constant Model Parameter(s)","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"When a neural network sets a constant model parameter value or an initial input, the input should be defined as a PEtab entity and specified directly in the mapping table (see above). This input can then be assigned in the parameters table or the conditions table using the setValue operator.","category":"page"},{"location":"format.html#Neural-Network-in-the-ODE-RHS-or-Observable-Formula","page":"Format","title":"Neural Network in the ODE RHS or Observable Formula","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"If the neural network appears in the ODE right-hand side or the observable formula, its input typically depends on model entities. Therefore, the input variable should be assigned using the setNetAssignment operator. For example, suppose net_input1 (mapped as a neural network input in the mapping table) should be assigned to species X:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"conditionId operatorType targetId targetValue\ncond1 setNetAssignment net_input1 X","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"In some cases, a neural network input may not correspond to a model variable (e.g., it could be a constant scalar). However, to ensure correct mapping, setNetAssignment must always be used for inputs when the neural network is part of the ODE RHS or observable formula.","category":"page"},{"location":"format.html#Additional-Details-2","page":"Format","title":"Additional Details","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The condition table and mapping table together specify where a neural network model is located in a PEtab SciML problem. In particular:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"If all inputs use setNetAssignment and all outputs use either setNetRate or setNetAssignment, the neural network appears in the ODE RHS.\nIf all inputs use setNetAssignment and no outputs appear in the condition table, the neural network is part of the observable formula (note though that the output variable must be referenced in the observable table).\nIf no inputs use setNetAssignment and all outputs use either setValue or setInitial, the neural network sets model parameters or initial values before the simulation.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"All other combinations are disallowed because they generally do not make sense in a PEtab context. For example, if inputs use setNetAssignment and outputs use setValue, the parameter values prior to simulation would be set via an assignment rule, which is not permitted in PEtab as, with other things, assignment rules might be time dependent. Naturally, implementations need to test that input combinations in the condition table are valid.","category":"page"},{"location":"format.html#Parameters-Table","page":"Format","title":"Parameters Table","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The parameter table follows the same format as in PEtab version 2 but extends it to accommodate neural network parameters and introduces new initializationPriorType for neural network-specific initialization. A general overview of the parameter table is available in the PEtab documentation; here, the focus is on extensions relevant to SciML extension.","category":"page"},{"location":"format.html#Detailed-Field-Descriptions-(Neural-Network-Extension)","page":"Format","title":"Detailed Field Descriptions (Neural Network Extension)","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId [String]: Identifies the neural network or a specific layer/parameter array. For example, layerId for netId can be specified using netId.layerId. A row for netId must be defined in the table. When parsing, more specific parameters (e.g., netId.layerId) take precedence for nominal values, priors, etc.\nnominalValue [String \\| NUMERIC]  Specifies neural network nominal values. This can be:\nA path to an HDF5 file that follows PyTorch syntax (recommended, see above for file format). If no file exists when the problem is imported and the parameters are set to be estimated, a file is created with randomly sampled values.\nA numeric value applied to all parameters under netId.\nestimate [0 \\| 1]: Indicates whether the parameters are estimated (1) or fixed (0). This must be consistent across layers. For example, if netId has estimate = 0, then netId.layerId must also be 0. In other words, freezing individual network parameters is not allowed.\ninitializationPriorType [String, OPTIONAL]: Specifies the prior used for sampling initial values before parameter estimation. In addition to the PEtab-supported priors [ADD], the SciML extension supports the following standard neural network initialization priors:\nkaimingUniform (default) — with gain as initializationPriorParameters value.\nkaimingNormal — with gain as initializationPriorParameters value.\nxavierUniform — with gain as initializationPriorParameters value.\nxavierNormal — with gain as initializationPriorParameters value.","category":"page"},{"location":"format.html#Example:-Different-Priors-for-Different-Layers","page":"Format","title":"Example: Different Priors for Different Layers","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Consider a neural-network model net1 where we want different initializationPriorParameters for layer1 and layer2, because they use different activation functions that should distinct gain for the kaimingUniform prior. A valid parameter table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId parameterScale lowerBound upperBound estimate nominalValue initializationPriorType initializationPriorParameters\nnet1 lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer1 lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer2 lin -inf inf 1 net1_ps.hf5 kaimingUniform 5/3","category":"page"},{"location":"format.html#Example:-Different-Priors-for-Parameters-in-a-Layer","page":"Format","title":"Example: Different Priors for Parameters in a Layer","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"Now consider we want to use different priors for the weights and bias in layer1 of net1, which is, for instance, a linear layer. A valid parameter table would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"parameterId parameterScale lowerBound upperBound estimate nominalValue initializationPriorType initializationPriorParameters\nnet1 lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer1.weight lin -inf inf 1 net1_ps.hf5 kaimingUniform 1\nnet1.layer1.bias lin -inf inf 1 net1_ps.hf5 kaimingNormal 5/3","category":"page"},{"location":"format.html#Additional-Details-3","page":"Format","title":"Additional Details","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"It is not possible to specify parameters at a level deeper than arrays. For example, in a linear layer, the deepest allowed specification is netId.layerId.weight.","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Bounds can be specified for an entire network or its nested levels. However, it should be noted that most optimization algorithms used for neural networks, such as ADAM, do not support parameter bounds in their standard implementation.","category":"page"},{"location":"format.html#Problem-YAML-File","page":"Format","title":"Problem YAML File","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"The PEtab problem YAML file follows the format of PEtab version 2, except that a mapping table is required (it is optional in the standard). It also includes an extension section to specify the neural network YAML files:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"extensions:\n  petab_sciml:\n    netId1:\n      file: \"file_path1.yaml\"\n    netId2:\n      file: \"file_path2.yaml\"","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"Here, netId1 and netId2 are the IDs of the neural network models. You can include any number of neural networks under petab_sciml.","category":"page"},{"location":"format.html#Example","page":"Format","title":"Example","text":"","category":"section"},{"location":"format.html","page":"Format","title":"Format","text":"For a model with one neural network, with ID net1, a valid YAML file would be:","category":"page"},{"location":"format.html","page":"Format","title":"Format","text":"format_version: 2\nproblems:\n  - model_files:\n      model_sbml:\n        location: \"model.xml\"\n        language: \"sbml\"\n    measurement_files:\n      - \"measurements.tsv\"\n    observable_files:\n      - \"observables.tsv\"\n    condition_files:\n      - \"conditions.tsv\"\n    mapping_files:\n      - \"mapping_table.tsv\"\nparameter_file: \"parameters.tsv\"\nextensions:\n  petab_sciml:\n    net1:\n      file: \"net1.yaml\"","category":"page"},{"location":"index.html#PEtab-SciML-Extension","page":"Home","title":"PEtab SciML Extension","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"Brief introduction.","category":"page"},{"location":"index.html#Major-Highlights","page":"Home","title":"Major Highlights","text":"","category":"section"},{"location":"index.html#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"TODO: Dilan should the mkstd SciML functionality live here, then I guess we need to pip register this repository?","category":"page"},{"location":"index.html#Getting-help","page":"Home","title":"Getting help","text":"","category":"section"},{"location":"tutorial.html#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"The tutorials will consist of:","category":"page"},{"location":"tutorial.html","page":"Tutorial","title":"Tutorial","text":"Overarching tutorial where we show how to Lotka-Voltera problem from the UDE paper.\nExtended tutorial 1 where we have a neural-network setting parameters, here it is also worthwhile to consider simulation conditions.\nExtended tutorial 2 where we have a neural network in the observable function.","category":"page"}]
}
